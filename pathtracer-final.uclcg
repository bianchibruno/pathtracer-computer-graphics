// filename: cw3_student.uclcg
// tabGroup: Coursework
// thumbnail: cw3_thumb.png
// displayname: Coursework 3 - 2022/2023
// shortDescription: Coursework 3 - Path Tracing
// author: None
// isHidden: false

function setup()
{
	UI = {};
	UI.tabs = [];
	UI.titleLong = 'Path Tracer';
	UI.titleShort = 'PathTracer';
	UI.numFrames = 5000;
	UI.maxFPS = 1000;
	UI.renderWidth = 512;
	UI.renderHeight = 256;

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Raytracing`,
		id: `TraceFS`,
		initialValue: `#define SOLUTION_LIGHT
#define SOLUTION_BOUNCE
#define SOLUTION_THROUGHPUT
#define SOLUTION_HALTON
#define SOLUTION_AA
#define SOLUTION_IS
//#define SOLUTION_MB


//for the unit test that checks whether our getRandomDirection function actually gets a random
//direction, we will generate normalized random direction vectors all across the image and convert
//them into colors. When we run the code, the average of the colors computed in the image should 
//converge to grey (vec3(0.5, 0.5, 0.5)).
//#define UNIT_TEST_DIRECTION

precision highp float;

#define M_PI 3.1415

struct Material {
	#ifdef SOLUTION_LIGHT
	vec3 radiance;
	#endif
	vec3 diffuse;
	vec3 specular;
	float glossiness;
};

struct Sphere {
	vec3 position;
#ifdef SOLUTION_MB
	vec3 motion;
#endif
	float radius;
	Material material;
};

struct Plane {
	vec3 normal;
	float d;
	Material material;
};

const int sphereCount = 4;
const int planeCount = 4;
const int emittingSphereCount = 2;
#ifdef SOLUTION_BOUNCE
const int maxPathLength = 2;
#else
const int maxPathLength = 1;
#endif

struct Scene {
	Sphere[sphereCount] spheres;
	Plane[planeCount] planes;
};

struct Ray {
	vec3 origin;
	vec3 direction;
};

// Contains all information pertaining to a ray/object intersection
struct HitInfo {
	bool hit;
	float t;
	vec3 position;
	vec3 normal;
	Material material;
};

// Contains info to sample a direction and this directions probability
struct DirectionSample {
	vec3 direction;
	float probability;
};

HitInfo getEmptyHit() {
	Material emptyMaterial;
	#ifdef SOLUTION_LIGHT
	emptyMaterial.radiance = vec3(0.0);
	#endif
	emptyMaterial.diffuse = vec3(0.0);
	emptyMaterial.specular = vec3(0.0);
	emptyMaterial.glossiness = 0.0;
	return HitInfo(false, 0.0, vec3(0.0), vec3(0.0), emptyMaterial);
}

// Sorts the two t values such that t1 is smaller than t2
void sortT(inout float t1, inout float t2) {
	// Make t1 the smaller t
	if(t2 < t1)  {
		float temp = t1;
		t1 = t2;
		t2 = temp;
	}
}

// Tests if t is in an interval
bool isTInInterval(const float t, const float tMin, const float tMax) {
	return t > tMin && t < tMax;
}

// Get the smallest t in an interval
bool getSmallestTInInterval(float t0, float t1, const float tMin, const float tMax, inout float smallestTInInterval) {

	sortT(t0, t1);

	// As t0 is smaller, test this first
	if(isTInInterval(t0, tMin, tMax)) {
		smallestTInInterval = t0;
		return true;
	}

	// If t0 was not in the interval, still t1 could be
	if(isTInInterval(t1, tMin, tMax)) {
		smallestTInInterval = t1;
		return true;
	}

	// None was
	return false;
}

// Converts a random integer in 15 bits to a float in (0, 1)
float randomInetegerToRandomFloat(int i) {
	return float(i) / 32768.0;
}

// Returns a random integer for every pixel and dimension that remains the same in all iterations
int pixelIntegerSeed(const int dimensionIndex) {
	vec3 p = vec3(gl_FragCoord.xy, dimensionIndex);
	vec3 r = vec3(23.14069263277926, 2.665144142690225,7.358926345 );
	return int(32768.0 * fract(cos(dot(p,r)) * 123456.0));
}

// Returns a random float for every pixel that remains the same in all iterations
float pixelSeed(const int dimensionIndex) {
	return randomInetegerToRandomFloat(pixelIntegerSeed(dimensionIndex));
}

// The global random seed of this iteration
// It will be set to a new random value in each step
uniform int globalSeed;
int randomSeed;
void initRandomSequence() {
	randomSeed = globalSeed + pixelIntegerSeed(0);
}

// Computes integer  x modulo y not available in most WEBGL SL implementations
int mod(const int x, const int y) {
	return int(float(x) - floor(float(x) / float(y)) * float(y));
}

// Returns the next integer in a pseudo-random sequence
int rand() {
	randomSeed = randomSeed * 1103515245 + 12345;
	return mod(randomSeed / 65536, 32768);
}

// Returns the next float in this pixels pseudo-random sequence
float uniformRandom() {
	return randomInetegerToRandomFloat(rand());
}

// Returns the ith prime number for the first 20
const int maxDimensionCount = 10;
int prime(const int index) {
	if(index == 0) return 2;
	if(index == 1) return 3;
	if(index == 2) return 5;
	if(index == 3) return 7;
	if(index == 4) return 11;
	if(index == 5) return 13;
	if(index == 6) return 17;
	if(index == 7) return 19;
	if(index == 8) return 23;
	if(index == 9) return 29;
	if(index == 10) return 31;
	if(index == 11) return 37;
	if(index == 12) return 41;
	if(index == 13) return 43;
	if(index == 14) return 47;
	if(index == 15) return 53;
	return 2;
}

#ifdef SOLUTION_HALTON
#endif

float halton(const int sampleIndex, const int dimensionIndex) {
	#ifdef SOLUTION_HALTON
	//pseudocode taken from https://en.wikipedia.org/wiki/Halton_sequence.
	//Cranley-Patterson rotation adjustment research from https://psychopath.io/post/2014_06_28_low_discrepancy_sequences.
	float b = float(prime(dimensionIndex));
	float i = float(sampleIndex);
	float r = 0.0;
	float f = 1.0;
	int counter = 0;
	for (int j = 0; j < 10000; j++){
		if (i > 0.0) {
			f /= b;
			r += f * float(mod(i,b));
			i = floor(i/b); 
		} else {
			break;
		}	
	}
	//Without Cranley-Patterson rotation adjustment, we would simply return fract(r). However, we can get rid of
	//patterned appearance of variance (resultant from taking numbers from a deterministic pseudo-random sequence of numbers) by adding a 
	// per-pixel and per-dimension random offset pixelSeed(dimensionIndex).
	r += pixelSeed(dimensionIndex);	
	return fract(r);
	
	#else
	// Put your implementation of halton in the #ifdef above 
	return 0.0;
	#endif
}

// This is the index of the sample controlled by the framework.
// It increments by one in every call of this shader
uniform int baseSampleIndex;

// Returns a well-distributed number in (0,1) for the dimension dimensionIndex
float sample(const int dimensionIndex) {
	#ifdef SOLUTION_HALTON
	return(halton(baseSampleIndex, dimensionIndex));
	#else
	// Use the Halton sequence for variance reduction in the #ifdef above
	return uniformRandom();
	#endif
}

// This is a helper function to sample two-dimensionaly in dimension dimensionIndex
vec2 sample2(const int dimensionIndex) {
	return vec2(sample(dimensionIndex + 0), sample(dimensionIndex + 1));
}

vec3 sample3(const int dimensionIndex) {
	return vec3(sample(dimensionIndex + 0), sample(dimensionIndex + 1), sample(dimensionIndex + 2));
}


// This is a register of all dimensions that we will want to sample.
// Thanks to Iliyan Georgiev from Solid Angle for explaining proper housekeeping of sample dimensions in ranomdized Quasi-Monte Carlo
//
// So if we want to use lens sampling, we call sample(LENS_SAMPLE_DIMENSION).
//
// There are infinitely many path sampling dimensions.
// These start at PATH_SAMPLE_DIMENSION.
// The 2D sample pair for vertex i is at PATH_SAMPLE_DIMENSION + PATH_SAMPLE_DIMENSION_MULTIPLIER * i + 0
#define ANTI_ALIAS_SAMPLE_DIMENSION 0
#define TIME_SAMPLE_DIMENSION 1
#define PATH_SAMPLE_DIMENSION 3

// This is 2 for two dimensions and 2 as we use it for two purposese: NEE and path connection
#define PATH_SAMPLE_DIMENSION_MULTIPLIER (2 * 2)

vec3 getEmission(const Material material, const vec3 normal) {
	//Humans perceive color in a non-linear way, we have greater sensitivity to differences between darker tones than to lighter ones.
	//The gamma value is used to correct the way an image is encoded, to avoid allocating too many bits to parts of the image that
	//we cannot differentiate, this is called gamma correction.
	#ifdef SOLUTION_LIGHT
	return material.radiance;
	#else
	// This is wrong. It just returns the diffuse color so that you see something to be sure it is working.
	return material.diffuse;
	#endif
}

vec3 getReflectance(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	//using physically-correct phong ray equation which is given in the pdf. This has the form a + b * c.
	vec3 a = material.diffuse / M_PI;
	//note we multiply the specular index by the normalization factor of n+2/2Ï€
	vec3 b = material.specular*((material.glossiness+2.0)/(2.0*M_PI));
	//we now calculate the unit vector of the reflected ray, which is reflected by the same angle as the incident ray with respect
	//to the normal. The formula used is 'r = d-2(d x n)n' taken from
	//https://math.stackexchange.com/questions/13261/how-to-get-a-reflection-vector
	vec3 unit_reflectance = inDirection - 2.0 * dot(inDirection, normal) * normal;
	//we neglect any negative values.
	float correct = max(0.0, dot(normalize(outDirection), normalize(unit_reflectance)));
	float c = pow(correct, material.glossiness);
	vec3 reflectance = a + b * c;
	return reflectance;
	#else
	return vec3(1.0);
	#endif
}

vec3 getGeometricTerm(const Material material, const vec3 normal, const vec3 inDirection, const vec3 outDirection) {
	#ifdef SOLUTION_THROUGHPUT
	//To calculate the geometric term, we simply need to calculate the cosine of the angle between the reflected ray
	//and the normal.
	float geometric = max(0.0,dot(normalize(normal), normalize(outDirection)));
	return vec3(geometric);
	#else
	return vec3(1.0);
	#endif
}

vec3 sphericalToEuclidean(float theta, float phi) {
	float x = sin(theta) * cos(phi);
	float y = sin(theta) * sin(phi);
	float z = cos(theta);
	return vec3(x, y, z);	
}

vec2 randomSphericalCoord(float eps0, float eps1){
	float theta = acos(2.0 * eps0 - 1.0);
	float phi = eps1 * 2.0 * M_PI;
	return vec2(theta, phi);
}

float lengthSquared(const vec3 x) {
	return dot(x, x);
}

vec3 getRandomDirection(const int dimensionIndex) {
	#ifdef SOLUTION_BOUNCE
	vec2 eps = sample2(dimensionIndex);
	//calculating spherical coordinates
	//To do this using three functions, we can create separate functions like getTheta and getPhi
	//instead of calculating both in the same function as done in the function I implemented
	//'randomSphericalCoord' (line 306).
	vec2 sphVec = randomSphericalCoord(eps[0], eps[1]);
	vec3 eucVec = sphericalToEuclidean(sphVec[0], sphVec[1]);
	
	#ifdef UNIT_TEST_DIRECTION
	if (abs(lengthSquared(eucVec) - 1.0) > 0.0001){
		return vec3(0.0);
	}
	#endif
	return eucVec;
	#else
	// Put your code to compute a random direction in 3D in the #ifdef above
	return vec3(0);
	#endif
}


HitInfo intersectSphere(const Ray ray, Sphere sphere, const float tMin, const float tMax) {

#ifdef SOLUTION_MB
	if (sphere.motion != vec3(0.0)){
		sphere.position += uniformRandom() * sphere.motion;
	}
#endif
	
	vec3 to_sphere = ray.origin - sphere.position;

	float a = dot(ray.direction, ray.direction);
	float b = 2.0 * dot(ray.direction, to_sphere);
	float c = dot(to_sphere, to_sphere) - sphere.radius * sphere.radius;
	float D = b * b - 4.0 * a * c;
	if (D > 0.0)
	{
		float t0 = (-b - sqrt(D)) / (2.0 * a);
		float t1 = (-b + sqrt(D)) / (2.0 * a);

		float smallestTInInterval;
		if(!getSmallestTInInterval(t0, t1, tMin, tMax, smallestTInInterval)) {
			return getEmptyHit();
		}

		vec3 hitPosition = ray.origin + smallestTInInterval * ray.direction;

		vec3 normal =
			length(ray.origin - sphere.position) < sphere.radius + 0.001?
			-normalize(hitPosition - sphere.position) :
		normalize(hitPosition - sphere.position);

		return HitInfo(
			true,
			smallestTInInterval,
			hitPosition,
			normal,
			sphere.material);
	}
	return getEmptyHit();
}

HitInfo intersectPlane(Ray ray, Plane plane) {
	float t = -(dot(ray.origin, plane.normal) + plane.d) / dot(ray.direction, plane.normal);
	vec3 hitPosition = ray.origin + t * ray.direction;
	return HitInfo(
		true,
		t,
		hitPosition,
		normalize(plane.normal),
		plane.material);
	return getEmptyHit();
}



HitInfo intersectScene(Scene scene, Ray ray, const float tMin, const float tMax)
{
	HitInfo best_hit_info;
	best_hit_info.t = tMax;
	best_hit_info.hit = false;

	for (int i = 0; i < sphereCount; ++i) {
		Sphere sphere = scene.spheres[i];
		HitInfo hit_info = intersectSphere(ray, sphere, tMin, tMax);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	for (int i = 0; i < planeCount; ++i) {
		Plane plane = scene.planes[i];
		HitInfo hit_info = intersectPlane(ray, plane);

		if(	hit_info.hit &&
		   hit_info.t < best_hit_info.t &&
		   hit_info.t > tMin)
		{
			best_hit_info = hit_info;
		}
	}

	return best_hit_info;
}

mat3 transpose(mat3 m) {
	return mat3(
		m[0][0], m[1][0], m[2][0],
		m[0][1], m[1][1], m[2][1],
		m[0][2], m[1][2], m[2][2]
	);
}

// This function creates a matrix to transform from global space into a local space oriented around the normal.
// Might be useful for importance sampling BRDF / the geometric term.
mat3 makeLocalFrame(const vec3 normal) {
	#ifdef SOLUTION_IS
	vec3 p;
	if (abs(normal.x) > abs(normal.y)){
		p = vec3(normal.z, 0, -normal.x) / sqrt(normal.x * normal.x + normal.z * normal.z);
	} else {
		p = vec3(0, -normal.z, normal.y) / sqrt(normal.y * normal.y + normal.z * normal.z);
	}
	vec3 p2 = cross(p, normal);
	return mat3(p, p2, normal);
	#else
	return mat3(1.0);
	#endif
}

vec3 sampleCosine(const int dimensionIndex) {
	vec2 xi = sample2(dimensionIndex);
	
	float theta = asin(sqrt(xi[0]));
	float phi = 2.0 * M_PI * xi[1];
	
	return sphericalToEuclidean(theta, phi); 
}

float cosineProbability(vec3 sampleDirection, vec3 normal) {
	float cosTheta = dot(sampleDirection, normal);
	return max(0.0, 1.0 / M_PI * cosTheta);  // if less than 0.0, then it is not within the hemisphere
}

DirectionSample sampleDirection(const vec3 normal, const int dimensionIndex) {
	DirectionSample result;

	#ifdef SOLUTION_IS
	//instead of distributing uniformly, we now distribute with cos(theta) pdf.
	//https://computergraphics.stackexchange.com/questions/4979/what-is-importance-sampling
	//https://alexanderameye.github.io/notes/sampling-the-hemisphere/
	
	//Importance sampling should make images resemble more the final product with less samples generated
	//as we can generate samples that match better the distribution of rays given by the ray equation.
	//In this case, as the ray equation has a cosine factor in it, instead of generating rays randomly,
	//we will generate rays following a cosine distribution.
	
	//For infinitely many samples, the difference between an importance sampled image and a randomly sampled
	//image should be negligible, as the importance sampled image will just converge quicker but the final
	//product they are converging into is the same product.
	vec2 rand = sample2(dimensionIndex);
	float theta = asin(sqrt(rand[0]));
	float phi = 2.0 * M_PI * rand[1];
	
	result.direction = makeLocalFrame(normal) * sphericalToEuclidean(theta, phi);
	
	
	float cosValue = dot(result.direction, normal);
	float cosProb = max(0.0, 1.0 / M_PI * cosValue);
	
	result.probability = cosProb;
	#else
	// Put yout code to compute Importance Sampling in the #ifdef above 
	result.direction = getRandomDirection(dimensionIndex);	
	result.probability = 1.0;
	#endif
	return result;
}

vec3 samplePath(const Scene scene, const Ray initialRay) {
	
	#ifdef UNIT_TEST_DIRECTION
	return (abs(getRandomDirection(0)));
	#endif
	// Initial result is black
	vec3 result = vec3(0);

	Ray incomingRay = initialRay;
	vec3 throughput = vec3(1.0);
	for(int i = 0; i < maxPathLength; i++) {
		HitInfo hitInfo = intersectScene(scene, incomingRay, 0.001, 10000.0);

		if(!hitInfo.hit) return result;

		result += throughput * getEmission(hitInfo.material, hitInfo.normal);

		Ray outgoingRay;
		DirectionSample directionSample;
		#ifdef SOLUTION_BOUNCE
		directionSample = sampleDirection(hitInfo.normal, i);
		outgoingRay.origin = hitInfo.position;
		outgoingRay.direction = directionSample.direction;
		#else
		// Put your code to compute the next ray in the #ifdef above
		#endif

		#ifdef SOLUTION_THROUGHPUT
		vec3 geometric = getGeometricTerm(hitInfo.material, hitInfo.normal, incomingRay.direction, outgoingRay.direction);
		vec3 reflectance = getReflectance(hitInfo.material, hitInfo.normal, incomingRay.direction, outgoingRay.direction);
		throughput *= geometric*reflectance;
		#else
		// Compute the proper throughput in the #ifdef above 
		throughput *= 0.1;
		#endif

		#ifdef SOLUTION_IS
		throughput /= directionSample.probability * 4.0 * M_PI;
		#else
		// Without Importance Sampling, there is nothing to do here. 
		// Put your Importance Sampling code in the #ifdef above
		#endif

		#ifdef SOLUTION_BOUNCE
		incomingRay = outgoingRay;
		#else
		// Put some handling of the next and the current ray in the #ifdef above
		#endif
	}
	return result;
}

uniform ivec2 resolution;
Ray getFragCoordRay(const vec2 fragCoord) {

	float sensorDistance = 1.0;
	vec3 origin = vec3(0, 0, sensorDistance);
	vec2 sensorMin = vec2(-1, -0.5);
	vec2 sensorMax = vec2(1, 0.5);
	vec2 pixelSize = (sensorMax - sensorMin) / vec2(resolution);
	vec3 direction = normalize(vec3(sensorMin + pixelSize * fragCoord, -sensorDistance));

	float apertureSize = 0.0;
	float focalPlane = 100.0;
	vec3 sensorPosition = origin + focalPlane * direction;
	origin.xy += -vec2(0.5);
	direction = normalize(sensorPosition - origin);

	return Ray(origin, direction);
}

vec3 colorForFragment(const Scene scene, const vec2 fragCoord) {
	initRandomSequence();

	#ifdef SOLUTION_AA
	//AA by box blur. We are working with pixels, so we will be focusing in pixels around our selected pixel, that is,
	//pixels that are a distance of +-0.5 vertically and horizontally. Sample helps us do this, as it generates a random
	//number in the range (0,1), so sample(anyVariable)-0.5 generates numbers in the range (-0.5, 0.5).
	float r0 = sample(ANTI_ALIAS_SAMPLE_DIMENSION)-0.5;
	float r1 = sample(ANTI_ALIAS_SAMPLE_DIMENSION + 1)-0.5;
	//given coordinate + random shift vector.
	vec2 sampleCoord = fragCoord+vec2(r0, r1);
	
	#else  	
	// Put your anti-aliasing code in the #ifdef above
	vec2 sampleCoord = fragCoord;
	#endif
	return samplePath(scene, getFragCoordRay(sampleCoord));
}


void loadScene1(inout Scene scene) {

	scene.spheres[0].position = vec3( 7, -2, -12);
	scene.spheres[0].radius = 2.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT
	scene.spheres[0].material.radiance = vec3(150.0*0.9, 150.0*0.9, 150.0*0.5);
#endif
	scene.spheres[0].material.diffuse = vec3(0.0);
	scene.spheres[0].material.specular = vec3(0.0);
	scene.spheres[0].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[0].motion = vec3(0.0);
#endif
	
	scene.spheres[1].position = vec3(-8, 4, -13);
	scene.spheres[1].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT
	scene.spheres[1].material.radiance = vec3(150.0*0.8, 150.0*0.3, 150.0*0.1);
#endif
	scene.spheres[1].material.diffuse = vec3(0.0);
	scene.spheres[1].material.specular = vec3(0.0);
	scene.spheres[1].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[1].motion = vec3(0.0);
#endif
	
	scene.spheres[2].position = vec3(-2, -2, -12);
	scene.spheres[2].radius = 3.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[2].material.radiance = vec3(0.0);
#endif  
	scene.spheres[2].material.diffuse = vec3(0.2, 0.5, 0.8);
	scene.spheres[2].material.specular = vec3(0.8);
	scene.spheres[2].material.glossiness = 40.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[2].motion = vec3(-3.0,0.0,3.0);
#endif
	
	scene.spheres[3].position = vec3(3, -3.5, -14);
	scene.spheres[3].radius = 1.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.spheres[3].material.radiance = vec3(0.0);
#endif  
	scene.spheres[3].material.diffuse = vec3(0.9, 0.8, 0.8);
	scene.spheres[3].material.specular = vec3(1.0);
	scene.spheres[3].material.glossiness = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_MB
	scene.spheres[3].motion = vec3(2.0,4.0,1.0);
#endif
	
	scene.planes[0].normal = vec3(0, 1, 0);
	scene.planes[0].d = 4.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT
	scene.planes[0].material.radiance = vec3(0.0);
#endif
	scene.planes[0].material.diffuse = vec3(0.8);
	scene.planes[0].material.specular = vec3(0);
	scene.planes[0].material.glossiness = 50.0;    

	scene.planes[1].normal = vec3(0, 0, 1);
	scene.planes[1].d = 18.5;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT    
	scene.planes[1].material.radiance = vec3(0.0);
#endif
	scene.planes[1].material.diffuse = vec3(0.9, 0.6, 0.3);
	scene.planes[1].material.specular = vec3(0.02);
	scene.planes[1].material.glossiness = 3000.0;

	scene.planes[2].normal = vec3(1, 0,0);
	scene.planes[2].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.planes[2].material.radiance = vec3(0.0);
#endif
	
	scene.planes[2].material.diffuse = vec3(0.2);
	scene.planes[2].material.specular = vec3(0.1);
	scene.planes[2].material.glossiness = 100.0; 

	scene.planes[3].normal = vec3(-1, 0,0);
	scene.planes[3].d = 10.0;
	// Set the value of the missing property in the ifdef below 
#ifdef SOLUTION_LIGHT  
	scene.planes[3].material.radiance = vec3(0.0);
#endif
	
	scene.planes[3].material.diffuse = vec3(0.2);
	scene.planes[3].material.specular = vec3(0.1);
	scene.planes[3].material.glossiness = 100.0; 
}


void main() {
	// Setup scene
	Scene scene;
	loadScene1(scene);

	// compute color for fragment
	gl_FragColor.rgb = colorForFragment(scene, gl_FragCoord.xy);
	gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: true,
		type: `x-shader/x-fragment`,
		title: `Tonemapping`,
		id: `CopyFS`,
		initialValue: `precision highp float;

uniform sampler2D radianceTexture;
uniform int sampleCount;
uniform ivec2 resolution;

vec3 tonemap(vec3 color, float maxLuminance, float gamma) {
	float luminance = length(color);
	//float scale =  luminance /  maxLuminance;
	float scale =  luminance / (maxLuminance * luminance + 0.0000001);
  	return max(vec3(0.0), pow(scale * color, vec3(1.0 / gamma)));
}

void main(void) {
  vec3 texel = texture2D(radianceTexture, gl_FragCoord.xy / vec2(resolution)).rgb;
  vec3 radiance = texel / float(sampleCount);
  gl_FragColor.rgb = tonemap(radiance, 1.0, 1.6);
  gl_FragColor.a = 1.0;
}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	UI.tabs.push(
		{
		visible: false,
		type: `x-shader/x-vertex`,
		title: ``,
		id: `VS`,
		initialValue: `
	attribute vec3 position;
	void main(void) {
		gl_Position = vec4(position, 1.0);
	}
`,
		description: ``,
		wrapFunctionStart: ``,
		wrapFunctionEnd: ``
	});

	 return UI; 
}//!setup


function getShader(gl, id) {

		gl.getExtension('OES_texture_float');
		//alert(gl.getSupportedExtensions());

	var shaderScript = document.getElementById(id);
	if (!shaderScript) {
		return null;
	}

	var str = "";
	var k = shaderScript.firstChild;
	while (k) {
		if (k.nodeType == 3) {
			str += k.textContent;
		}
		k = k.nextSibling;
	}

	var shader;
	if (shaderScript.type == "x-shader/x-fragment") {
		shader = gl.createShader(gl.FRAGMENT_SHADER);
	} else if (shaderScript.type == "x-shader/x-vertex") {
		shader = gl.createShader(gl.VERTEX_SHADER);
	} else {
		return null;
	}

    console.log(str);
	gl.shaderSource(shader, str);
	gl.compileShader(shader);

	if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
		alert(gl.getShaderInfoLog(shader));
		return null;
	}

	return shader;
}

function RaytracingDemo() {
}

function initShaders() {

	traceProgram = gl.createProgram();
	gl.attachShader(traceProgram, getShader(gl, "VS"));
	gl.attachShader(traceProgram, getShader(gl, "TraceFS"));
	gl.linkProgram(traceProgram);
	gl.useProgram(traceProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(traceProgram, "position");
	gl.enableVertexAttribArray(traceProgram.vertexPositionAttribute);

	copyProgram = gl.createProgram();
	gl.attachShader(copyProgram, getShader(gl, "VS"));
	gl.attachShader(copyProgram, getShader(gl, "CopyFS"));
	gl.linkProgram(copyProgram);
	gl.useProgram(copyProgram);
	traceProgram.vertexPositionAttribute = gl.getAttribLocation(copyProgram, "position");
	gl.enableVertexAttribArray(copyProgram.vertexPositionAttribute);

}

function initBuffers() {
	triangleVertexPositionBuffer = gl.createBuffer();
	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);

	var vertices = [
		 -1,  -1,  0,
		 -1,  1,  0,
		 1,  1,  0,

		 -1,  -1,  0,
		 1,  -1,  0,
		 1,  1,  0,
	 ];
	gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);
	triangleVertexPositionBuffer.itemSize = 3;
	triangleVertexPositionBuffer.numItems = 3 * 2;
}


function tick() {

// 1st pass: Trace
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	gl.useProgram(traceProgram);
  	gl.uniform1i(gl.getUniformLocation(traceProgram, "globalSeed"), Math.random() * 32768.0);
	gl.uniform1i(gl.getUniformLocation(traceProgram, "baseSampleIndex"), getCurrentFrame());
	gl.uniform2i(
		gl.getUniformLocation(traceProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		traceProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.enable(gl.BLEND);
	gl.blendFunc(gl.ONE, gl.ONE);

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

// 2nd pass: Average
   	gl.bindFramebuffer(gl.FRAMEBUFFER, null);

	gl.useProgram(copyProgram);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "sampleCount"), getCurrentFrame() + 1);

	gl.bindBuffer(gl.ARRAY_BUFFER, triangleVertexPositionBuffer);
	gl.vertexAttribPointer(
		copyProgram.vertexPositionAttribute,
		triangleVertexPositionBuffer.itemSize,
		gl.FLOAT,
		false,
		0,
		0);

    	gl.viewport(0, 0, gl.viewportWidth, gl.viewportHeight);

	gl.disable(gl.DEPTH_TEST);
	gl.disable(gl.BLEND);

	gl.activeTexture(gl.TEXTURE0);
    	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
	gl.uniform1i(gl.getUniformLocation(copyProgram, "radianceTexture"), 0);
	gl.uniform2i(
		gl.getUniformLocation(copyProgram, "resolution"),
		getRenderTargetWidth(),
		getRenderTargetHeight());

	gl.drawArrays(gl.TRIANGLES, 0, triangleVertexPositionBuffer.numItems);

	gl.bindTexture(gl.TEXTURE_2D, null);
}

function init() {
	initShaders();
	initBuffers();
	gl.clear(gl.COLOR_BUFFER_BIT);

	rttFramebuffer = gl.createFramebuffer();
	gl.bindFramebuffer(gl.FRAMEBUFFER, rttFramebuffer);

	rttTexture = gl.createTexture();
	gl.bindTexture(gl.TEXTURE_2D, rttTexture);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    	gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);

	gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, getRenderTargetWidth(), getRenderTargetHeight(), 0, gl.RGBA, gl.FLOAT, null);

	gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, rttTexture, 0);
}

var oldWidth = 0;
var oldTraceProgram;
var oldCopyProgram;
function compute(canvas) {

	if(	getRenderTargetWidth() != oldWidth ||
		oldTraceProgram != document.getElementById("TraceFS") ||
		oldCopyProgram !=  document.getElementById("CopyFS"))
	{
		init();

		oldWidth = getRenderTargetWidth();
		oldTraceProgram = document.getElementById("TraceFS");
		oldCopyProgram = document.getElementById("CopyFS");
	}

	tick();
}
